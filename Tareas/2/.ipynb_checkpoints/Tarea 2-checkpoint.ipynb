{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "excellent-external",
   "metadata": {},
   "source": [
    "1. Programe el algoritmo de Metrópolis-Hastings (MH) con caminata aleatoria Gaussiana para la distribución de propuesta en el lenguaje de programación de su preferencia para simular $\\left(X_{1}, X_{2}\\right)$ tales que $X_{1}, X_{2}$ marginalmente tienen distribución $\\operatorname{Beta}(0.5,0.5)$ y Gamma $(20,4)$ respectivamente $\\mathrm{y}$ estructura de dependencia dada por una cópula de Clayton con parámetro $\\theta \\in\\{0.1,1,10\\}$. (4 pts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-oregon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "criminal-anatomy",
   "metadata": {},
   "source": [
    "2. Muestre directamente que el algoritmo de Gibbs satisace la condición de balance detallado (en particular no es valido para el ejercicio usar que el algoritmo de Gibbs puede ser interpretado como caso particular de Metropolis-Hastings). (2 pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handmade-termination",
   "metadata": {},
   "source": [
    "Sea $Y=\\left(Y_{1}, Y_{2}\\right)^{\\top}$ entonces la actulización de  $Y^{(t+1)}$ en el tiempo $t+1$ se obtiene del anterio $Y^{(t)}$ en dos pasos:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Y_{1}^{(t+1)} & \\sim p\\left(y_{1} \\mid Y_{2}^{(t)}\\right) \\\\\n",
    "Y_{2}^{(t+1)} & \\sim p\\left(y_{2} \\mid Y_{1}^{(t+1)}\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "De acuerdo con la matriz de transición $P\\left(y, y^{\\prime}\\right)=\\mathbb{P}\\left(Y^{(t+1)}=y^{\\prime} \\mid Y^{(t)}=y\\right)$ se puede factorizar en dos matrices de transicion saperadas\n",
    "$$\n",
    "P\\left(y, y^{\\prime}\\right)=P_{1}(y, \\tilde{y}) P_{2}\\left(\\tilde{y}, y^{\\prime}\\right)\n",
    "$$\n",
    "donde $\\tilde{y}=\\left(y_{1}^{\\prime}, y_{2}\\right)^{\\top}$ es el resultado intermedio despues del primer paso. Por lo tanto se tiene\n",
    "$$\n",
    "P_{1}(y, \\tilde{y})=p\\left(y_{1}^{\\prime} \\mid y_{2}\\right) \\quad \\text { y } \\quad P_{2}\\left(\\tilde{y}, y^{\\prime}\\right)=p\\left(y_{2}^{\\prime} \\mid y_{1}^{\\prime}\\right) .\n",
    "$$\n",
    "\n",
    "Hay que observar que para cualquier $y, y^{\\prime}$, se tiene $P_{1}\\left(y, y^{\\prime}\\right)=0$ si $y_{2} \\neq y_{2}^{\\prime}$ y $P_{2}\\left(y, y^{\\prime}\\right)=0$ si $y_{1} \\neq y_{1}^{\\prime}$.\n",
    "\n",
    "De acuerdo con el equilibrio detallado de las cadenas de Markov dependientes del tiempo, basta con mostrar el equilibrio detallado de cada una de las matrices de transición para cualquier estado $y, y^{\\prime}$ tal que $y_{2}=y_{2}^{\\prime}$\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p(y) P_{1}\\left(y, y^{\\prime}\\right) &=p\\left(y_{1}, y_{2}\\right) p\\left(y_{1}^{\\prime} \\mid y_{2}\\right)=p\\left(y_{1} \\mid y_{2}\\right) p\\left(y_{1}^{\\prime}, y_{2}\\right) \\\\\n",
    "&=p\\left(y_{1} \\mid y_{2}^{\\prime}\\right) p\\left(y_{1}^{\\prime}, y_{2}^{\\prime}\\right)=P_{1}\\left(y^{\\prime}, y\\right) p\\left(y^{\\prime}\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "Mientras que para $y, y^{\\prime}$ con $y_{2} \\neq y_{2}^{\\prime}$ la ecuación se cumple trivialmente. De manera similar obtenemos para $y, y^{\\prime}$ tal que $y_{1}=y_{1}^{\\prime}$\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p(y) P_{2}\\left(y, y^{\\prime}\\right) &=p\\left(y_{1}, y_{2}\\right) p\\left(y_{2}^{\\prime} \\mid y_{1}\\right)=p\\left(y_{2} \\mid y_{1}\\right) p\\left(y_{2}^{\\prime}, y_{1}\\right) \\\\\n",
    "&=p\\left(y_{2} \\mid y_{1}^{\\prime}\\right) p\\left(y_{1}^{\\prime}, y_{2}^{\\prime}\\right)=P_{2}\\left(y^{\\prime}, y\\right) p\\left(y^{\\prime}\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "Mientras que para $y, y^{\\prime}$ con $y_{1} \\neq y_{1}^{\\prime}$ la ecuación se sostiene trivialmente. Todo junto esto demuestra que $p(y)$ es de hecho la distribución estacionaria del muestreador de Gibbs. Hay que tomar en cuenta que combinados obtenemos\n",
    "$$\n",
    "p(y) P\\left(y, y^{\\prime}\\right)=p(y) P_{1}(y, \\tilde{y}) P_{1}\\left(\\tilde{y}, y^{\\prime}\\right)=p\\left(y^{\\prime}\\right) P_{2}\\left(y^{\\prime}, \\tilde{y}\\right) P_{1}(\\tilde{y}, y) \\neq p\\left(y^{\\prime}\\right) P\\left(y^{\\prime}, y\\right)\n",
    "$$\n",
    "Las cadenas de Markov $\\left\\{Y_{t}\\right\\}$ que satisfacen la ecuación de equilibrio detallada se denominan reversibles en el tiempo, ya que se puede demostrar que\n",
    "$$\n",
    "\\mathbb{P}\\left(Y_{t+1}=y^{\\prime} \\mid Y_{t}=y\\right)=\\mathrm{P}\\left(Y_{t}=y \\mid Y_{t+1}=y^{\\prime}\\right)\n",
    "$$\n",
    "Para el muestreador Gibbs para retroceder en el tiempo, tenemos que actualizar los dos componentes en orden inverso: primero $Y_{2}^{(t+1)}$ y despues $Y_{1}^{(t+1)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-scheme",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "spare-director",
   "metadata": {},
   "source": [
    "3. Sean $n, d$ enteros positivos, $\\mu_{0} \\in \\mathbb{R}, \\boldsymbol{\\alpha}=\\left(\\alpha_{1}, \\ldots, \\alpha_{d}\\right) \\in\\left(\\mathbb{R}^{+}\\right)^{d} \\mathrm{y} \\alpha, \\beta, \\nu \\in \\mathbb{R}^{+}$. Considere\n",
    "el modelo probabilístico\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\lambda_{j} & \\sim \\operatorname{Gamma}(\\alpha, \\beta), & & j \\in\\{1, \\ldots, d\\} \\\\\n",
    "& \\Pi \\sim \\operatorname{Dirichlet}(\\boldsymbol{\\alpha}) & & \\\\\n",
    "Z_{i} \\mid \\Pi=\\pi & \\sim \\text { Categorico }(\\boldsymbol{\\pi}), & & i \\in\\{1, \\ldots, n\\} \\\\\n",
    "X_{i} \\mid Z_{i}=j, \\boldsymbol{\\lambda}, & \\sim \\operatorname{Poisson}\\left(\\lambda_{j}\\right), & i \\in\\{1, \\ldots, n\\}\n",
    "\\end{aligned}\n",
    "$$\n",
    "Determine las distribuciones condicionales\n",
    "donde $\\boldsymbol{v}_{\\cup}=\\left(v_{1}, \\ldots, v_{j-1}, v_{j+1}, \\ldots v_{d}\\right)$ es el vector conformado por las entradas de $\\boldsymbol{v}$ en orden sin incluir la entrada $j$. Recuerde que la densidad de una distribución Dirichlet está dada por\n",
    "$$\n",
    "f_{\\text {Dir }(\\alpha)}(x)=\\left(\\Gamma\\left(\\sum_{j+1}^{d} \\alpha_{j}\\right)\\right)^{-1} \\prod_{j=1}^{d} \\Gamma\\left(\\alpha_{j}\\right) x_{j}^{\\alpha_{j}-1}\n",
    "$$\n",
    "Implemente el muuestreador de Gibbs para $\\boldsymbol{\\lambda}, \\boldsymbol{\\pi}, \\boldsymbol{Z} \\mid X$ utilizando las distribuciones condicionales anteriores. (4 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-prime",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
